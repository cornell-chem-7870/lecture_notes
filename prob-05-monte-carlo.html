
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Monte Carlo &#8212; Lecture Notes for Cornell Chem 7870</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'prob-05-monte-carlo';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Markov Chain Monte Carlo" href="prob-06-mcmc.html" />
    <link rel="prev" title="Bayesian Inference" href="prob-04-bayesian-inference.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Lecture Notes for Cornell Chem 7870 - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="Lecture Notes for Cornell Chem 7870 - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to 7870
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 1. Linear Algebra</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="linalg-01-intro_vectors.html">A Deeper look at Vectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="linalg-02-coding_matrices_in_python.html">Linear Algebra in Python with Numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="linalg-03-matrix_decompositions.html">Eigenvectors, Unitary Matrices, and Matrix Decompositions</a></li>
<li class="toctree-l1"><a class="reference internal" href="linalg-04-linear_regression.html">Linear Regression and Least Squares</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 2. Optimization and Numerical Differential Equations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="optim-01-intro-optimization.html">Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim-02-nonlinear-optimization.html">Nonlinear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim-03a-autograd-in-pytorch.html">Automatic Differentiation and Pytorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim-03b-autograd-in-jax.html">Working in JaX</a></li>



<li class="toctree-l1"><a class="reference internal" href="diffeq-01-ode-intro.html">Intro to Numerical Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="diffeq-02-symplectic-integrators.html">More on Numerical ODEs</a></li>
<li class="toctree-l1"><a class="reference internal" href="diffeq-03-pde.html">From ODE to PDE</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 3. Probability</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="prob-01-probability.html">Intro to Probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="prob-02-random-in-numpy.html">Using Random Numbers in Numpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="prob-03-bayes-rule.html">Conditional Probability and Bayes Rule</a></li>
<li class="toctree-l1"><a class="reference internal" href="prob-04-bayesian-inference.html">Bayesian Inference</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Monte Carlo</a></li>
<li class="toctree-l1"><a class="reference internal" href="prob-06-mcmc.html">Markov Chain Monte Carlo</a></li>
<li class="toctree-l1"><a class="reference internal" href="prob-07-metropolis-hastings.html">Detailed Balance and the Metropolis-Hastings Algorithm</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fprob-05-monte-carlo.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/prob-05-monte-carlo.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Monte Carlo</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-problem-evaluating-high-dimensional-integrals">The Problem: Evaluating High-dimensional Integrals</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#monte-carlo-methods">Monte Carlo Methods</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convergence-of-monte-carlo">Convergence of Monte Carlo</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#monte-carlo-integration-calculating-pi">Monte Carlo Integration: Calculating Pi</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#monte-carlo-integration-calculating-posterior-means-by-sampling-the-prior">Monte Carlo Integration: Calculating Posterior Means by Sampling the Prior</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="monte-carlo">
<h1>Monte Carlo<a class="headerlink" href="#monte-carlo" title="Link to this heading">#</a></h1>
<section id="learning-objectives">
<h2>Learning Objectives<a class="headerlink" href="#learning-objectives" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Understand the basic mathematical principles behind Monte Carlo methods.</p></li>
<li><p>Be able to implement simple Monte Carlo Algorithms</p></li>
<li><p>Understand the convergence rate of Monte Carlo methods and what governs the error.</p></li>
</ul>
</section>
<section id="the-problem-evaluating-high-dimensional-integrals">
<h2>The Problem: Evaluating High-dimensional Integrals<a class="headerlink" href="#the-problem-evaluating-high-dimensional-integrals" title="Link to this heading">#</a></h2>
<p>In Bayesian inference, we might want to calculate the posterior mean, variance, or some other statistic.
To recap, the posterior distribution is given by Bayes’ theorem,</p>
<div class="math notranslate nohighlight">
\[
p(\theta|D) = \frac{p(D|\theta)p(\theta)}{p(D)}
\]</div>
<p>where <span class="math notranslate nohighlight">\(D\)</span> is the data, <span class="math notranslate nohighlight">\(\theta\)</span> is the parameter, <span class="math notranslate nohighlight">\(p(D|\theta)\)</span> is the likelihood, <span class="math notranslate nohighlight">\(p(\theta)\)</span> is the prior, and <span class="math notranslate nohighlight">\(p(D)\)</span> is the evidence.
The posterior mean is given by</p>
<div class="math notranslate nohighlight">
\[
E[\theta|D] = \int \theta p(\theta|D)d\theta
\]</div>
<p>and the posterior variance is given by</p>
<div class="math notranslate nohighlight">
\[
\text{Var}[\theta|D] = \int (\theta - E[\theta|D])^2 p(\theta|D)d\theta
\]</div>
<p>So far, we have calculated these expectations against the posterior distribution either analytically or
using numerical methods such as grid approximation or numerical integration.
Unfortunately, these methods do not scale well to high-dimensional problems.
Calculating the posterior requires evaluating the evidence,</p>
<div class="math notranslate nohighlight">
\[
p(D) = \int p(D|\theta)p(\theta)d\theta
\]</div>
<p>If we have a single parameter, this is trivial.  If we have three, we have to evaluate the integral over a three-dimensional space: not impossible, but potentially expensive.
If we have 100 parameters, we have to evaluate the integral over a 100-dimensional space: this is impossible using numerical integration.</p>
<p>We have a similar problem in statistical mechanics.
Most experimental measurements are averages over a large number of particles.
At thermal equilibrium, these averages are given by the Boltzmann distribution and are given by</p>
<div class="math notranslate nohighlight">
\[
  E[f] = \frac{\int f(x) e^{-\beta H(x)}dx}{\int e^{-\beta H(x')}dx'}
\]</div>
<p>where <span class="math notranslate nohighlight">\(f(x)\)</span> is the function we want to calculate, <span class="math notranslate nohighlight">\(H(x)\)</span> is the Hamiltonian, and <span class="math notranslate nohighlight">\(\beta = 1/kT\)</span>.
Each point <span class="math notranslate nohighlight">\(x\)</span> is a point in the phase space of the system, which is a 6N-dimensional space for a system with N particles.
Again, this is impossible to calculate using numerical integration for even modest values of N.
Clearly, we need another way to calculate these integrals.</p>
</section>
<section id="monte-carlo-methods">
<h2>Monte Carlo Methods<a class="headerlink" href="#monte-carlo-methods" title="Link to this heading">#</a></h2>
<p>So far, we have been considering a random variable and then calculating its expectation by integrating over a probability density.
Monte Carlo methods flip this paradigm.  Given a high-dimensional integral, we (1) find a way to write it as an expectation over a probability density, and then (2) estimate the expectation using random samples drawn from the corresponding distribution.
If we choose our random samples well, the law of large numbers tells us that the sample mean will converge to the expected value as the number of samples goes to infinity.</p>
<section id="convergence-of-monte-carlo">
<h3>Convergence of Monte Carlo<a class="headerlink" href="#convergence-of-monte-carlo" title="Link to this heading">#</a></h3>
<p>As a specific example, let’s assume we are estimating the expectation of a function <span class="math notranslate nohighlight">\(f(x)\)</span> over a probability density <span class="math notranslate nohighlight">\(p(x)\)</span>.
For simplicity, let’s assumed that the true expectation of <span class="math notranslate nohighlight">\(f(x)\)</span> is zero and its variance is <span class="math notranslate nohighlight">\(\sigma^2\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
E[f] &amp;= \int f(x) p(x) dx  = 0 \\
\text{Var}[f] &amp;= \int f(x)^2 p(x) dx = \sigma^2
\end{split}
\end{split}\]</div>
<p>We are going to approximate this expectation using a sample mean</p>
<div class="math notranslate nohighlight">
\[
\hat{E}[f] = \frac{1}{N}\sum_{i=1}^N f(x_i)
\]</div>
<p>where <span class="math notranslate nohighlight">\(x_i\)</span> are samples drawn independently and identically from the distribution associated with the density <span class="math notranslate nohighlight">\(p(x)\)</span>.  To evaluate
the error in this estimate, we will calculate the variance of the sample mean.</p>
<p>We first note that since our samples are drawn independently and identically, they have a probability density</p>
<div class="math notranslate nohighlight">
\[
p(x_1, x_2, \ldots, x_N) = p(x_1)p(x_2)\ldots p(x_N)
\]</div>
<p>We immediately see that the expectation of the sample mean is the true expectation</p>
<div class="math notranslate nohighlight">
\[
E[\hat{E}[f]] = E[ \frac{1}{N}\sum_{i=1}^N f(x_i)] = \frac{1}{N}\sum_{i=1}^N \int f(x_i) p(x_1) p(x_2) \ldots p(x_N) dx_i = \int f(x) p(x) dx = 0
\]</div>
<p>Consequently, the variance of the sample estimator is just given by the expectation of its square.</p>
<div class="math notranslate nohighlight">
\[
E[\hat{E}[f]^2] = E[\frac{1}{N^2}\sum_{i=1}^N \sum_{j=1}^N f(x_i)f(x_j)] = \frac{1}{N^2}\sum_{i=1}^N \sum_{j=1}^N \int f(x_i)f(x_j) p(x_1) p(x_2) \ldots p(x_N) dx_i dx_j
\]</div>
<p>Since the samples are drawn independently, these expectations are zero unless <span class="math notranslate nohighlight">\(i = j\)</span>.  Consequently, the variance of the sample mean is given by</p>
<div class="math notranslate nohighlight">
\[
\text{Var}[\hat{E}[f]] = \frac{1}{N^2}\sum_{i=1}^N \int f(x_i)^2 p(x_i) dx_i = \frac{\sigma^2}{N}
\]</div>
<p>This tells us that the variance of the sample mean decreases as <span class="math notranslate nohighlight">\(1/N\)</span>.  Similarly, we expect the root mean square error to decrease as <span class="math notranslate nohighlight">\(1/\sqrt{N}\)</span>.</p>
</section>
<section id="monte-carlo-integration-calculating-pi">
<h3>Monte Carlo Integration: Calculating Pi<a class="headerlink" href="#monte-carlo-integration-calculating-pi" title="Link to this heading">#</a></h3>
<p>As a simple demonstration of Monte Carlo integration, consider the problem of calculating <span class="math notranslate nohighlight">\(\pi\)</span>.
The area of a circle is given by <span class="math notranslate nohighlight">\(\pi r^2\)</span>.
The area of a square that circumscribes the circle, in turn, is given by <span class="math notranslate nohighlight">\(4r^2\)</span>.
Consequently, if we can calculate the fraction of the area of the square that is covered by the circle, we can calculate <span class="math notranslate nohighlight">\(\pi\)</span>: this fraction is given by <span class="math notranslate nohighlight">\(\pi/4\)</span>.
This fraction can be written as an expectation over a probability density:</p>
<div class="math notranslate nohighlight">
\[
\frac{\pi}{4} = \int_{-1}^1 \int_{-1}^1 \mathbb{1}(x^2 + y^2 \leq 1) p(x, y) dx dy
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbb{1}(x^2 + y^2 \leq 1)\)</span> is the indicator function that is 1 if <span class="math notranslate nohighlight">\(x^2 + y^2 \leq 1\)</span> and 0 otherwise,
and <span class="math notranslate nohighlight">\(p(x, y)\)</span> is the uniform distribution over the square.</p>
<p>To estimate this integral, we can draw <span class="math notranslate nohighlight">\(N\)</span> samples from the uniform distribution over the square and calculate the fraction of samples that fall within the circle.
The fraction of samples that fall within the circle will converge to <span class="math notranslate nohighlight">\(\pi/4\)</span> as <span class="math notranslate nohighlight">\(N\)</span> goes to infinity.  In code, this looks as follows:</p>
</section>
<section id="monte-carlo-integration-calculating-posterior-means-by-sampling-the-prior">
<h3>Monte Carlo Integration: Calculating Posterior Means by Sampling the Prior<a class="headerlink" href="#monte-carlo-integration-calculating-posterior-means-by-sampling-the-prior" title="Link to this heading">#</a></h3>
<p>Lets say we are attempting to calculate the posterior mean of a parameter <span class="math notranslate nohighlight">\(\theta\)</span> and the prior is a multi-dimensional Gaussian distribution.
We can approximate the posterior mean as follows:</p>
<ol class="arabic simple">
<li><p>Draw <span class="math notranslate nohighlight">\(N\)</span> samples from the prior distribution.</p></li>
<li><p>Calculate the likelihood for each sample.</p></li>
<li><p>Calculate the approximations</p></li>
</ol>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
p(D) = \int p(D|\theta)p(\theta)d\theta \approx \frac{1}{N}\sum_{i=1}^N p(D|\theta_i) \\
\int \theta p(\theta|D)d\theta \approx \frac{1}{N}\sum_{i=1}^N \theta_i p(\theta_i|D)
\end{split}
\end{split}\]</div>
<ol class="arabic simple" start="4">
<li><p>Calculate the posterior mean by dividing the two approximations.</p></li>
</ol>
<p>This gives a Monte Carlo estimate of the posterior mean.<br />
However, some caution is required.  While for small <span class="math notranslate nohighlight">\(N\)</span> this may be an efficient way to calculate the posterior mean, for large <span class="math notranslate nohighlight">\(N\)</span> we expect the likelihood to be very small unless <span class="math notranslate nohighlight">\(\theta\)</span> happens to be close to the true value.
In this case, the Monte Carlo estimate will have a large variance: most of our samples from <span class="math notranslate nohighlight">\(p(\theta)\)</span> will be far from the true value of <span class="math notranslate nohighlight">\(\theta\)</span> and will have a negligible likelihood.  Consequently, the Monte Carlo estimate will be dominated by the few samples that happen to have a large likelihood, and the estimate will be very noisy.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="prob-04-bayesian-inference.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Bayesian Inference</p>
      </div>
    </a>
    <a class="right-next"
       href="prob-06-mcmc.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Markov Chain Monte Carlo</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-problem-evaluating-high-dimensional-integrals">The Problem: Evaluating High-dimensional Integrals</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#monte-carlo-methods">Monte Carlo Methods</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convergence-of-monte-carlo">Convergence of Monte Carlo</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#monte-carlo-integration-calculating-pi">Monte Carlo Integration: Calculating Pi</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#monte-carlo-integration-calculating-posterior-means-by-sampling-the-prior">Monte Carlo Integration: Calculating Posterior Means by Sampling the Prior</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Erik Thiede
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>